{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from config import DATASET_PATH\n",
    "from datasets import (Dataset, RAVDESSLabel, TESSLabel, \n",
    "                     EMOVOLabel, SAVEELabel, MFCCData, WAVData,\n",
    "                     RAVDESSUnifiedLabel, TESSUnifiedLabel, SAVEEUnifiedLabel,\n",
    "                     EMOVOUnifiedLabel)\n",
    "\n",
    "from tools import add_margin, IndexPicker\n",
    "\n",
    "from classifiers import Sequential\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ravdess_path = DATASET_PATH.format(language=\"english\", name=\"RAVDESS\", form=\"mfcc\")\n",
    "\n",
    "ravdess_mfcc_unified = Dataset(ravdess_path, MFCCData(), RAVDESSUnifiedLabel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tess_path = DATASET_PATH.format(language=\"english\", name=\"TESS\", form=\"mfcc\")\n",
    "\n",
    "tess_mfcc_unified = Dataset(tess_path, MFCCData(), TESSUnifiedLabel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "savee_path = DATASET_PATH.format(language=\"english\", name=\"SAVEE\", form=\"mfcc\")\n",
    "\n",
    "savee_mfcc_unified = Dataset(savee_path, MFCCData(), SAVEEUnifiedLabel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "emovo_path = DATASET_PATH.format(language=\"italian\", name=\"EMOVO\", form=\"mfcc\")\n",
    "\n",
    "emovo_mfcc_unified = Dataset(emovo_path, MFCCData(), EMOVOUnifiedLabel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ravdess_mfcc_unified.combine(savee_mfcc_unified, tess_mfcc_unified, emovo_mfcc_unified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ravdess_mfcc_unified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = dataset.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(list(samples['coefficients']))\n",
    "\n",
    "y = np.array(list(samples['emotion']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1282163,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1282163, 39)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mass Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_picker = IndexPicker(25, 25)  # 25 25\n",
    "\n",
    "hidden_sizes = [128, 128, 128]\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "learning_rate = 0.0001\n",
    "\n",
    "n_epochs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.68 s, sys: 679 ms, total: 5.36 s\n",
      "Wall time: 5.41 s\n"
     ]
    }
   ],
   "source": [
    "%time X_margined = np.array(add_margin(X, index_picker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1282163, 3, 39)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_margined.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 390 ms, sys: 244 ms, total: 634 ms\n",
      "Wall time: 639 ms\n"
     ]
    }
   ],
   "source": [
    "n_samples,window_length,n_features = X_margined.shape\n",
    "%time X_reshaped = np.array(np.reshape(X_margined, (n_samples, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1282163, 117)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reshaped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin,BaseEstimator\n",
    "\n",
    "\n",
    "class Scaler(BaseEstimator,TransformerMixin):\n",
    "\n",
    "    def __init__(self, scaler):\n",
    "        self.scaler = scaler\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        self.scaler.fit(X.reshape(-1, 1))\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        return self.scaler.transform(X.reshape(-1, 1)).reshape(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepere for model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X_reshaped,\n",
    "    y,\n",
    "    stratify=y,\n",
    "    test_size=0.05,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full,\n",
    "    y_train_full,\n",
    "    stratify=y_train_full,\n",
    "    test_size=0.05,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# scaler = Scaler(StandardScaler())\n",
    "# %time X_train = scaler.fit_transform(X_train)    ## fit it only on train data\n",
    "# %time X_valid = scaler.transform(X_valid)\n",
    "# %time X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1157151, 117)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "def prepare_torch_dataset(batch_size, X, y):\n",
    "    tensor_x = torch.Tensor(X)\n",
    "    tensor_y = torch.Tensor(y).type(torch.LongTensor)\n",
    "\n",
    "    dataset = TensorDataset(tensor_x, tensor_y)\n",
    "    datasetloader = DataLoader(dataset, batch_size=batch_size)\n",
    "    return dataset, datasetloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, train_loader = prepare_torch_dataset(batch_size, X_train, y_train)\n",
    "\n",
    "valset, val_loader = prepare_torch_dataset(batch_size, X_valid, y_valid)\n",
    "\n",
    "testset, test_loader = prepare_torch_dataset(batch_size, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "input_size = n_features\n",
    "output_size = n_classes\n",
    "\n",
    "input_layer = [\n",
    "    nn.Linear(input_size, hidden_sizes[0]),\n",
    "    nn.ReLU()\n",
    "]\n",
    "\n",
    "output_layer = [nn.Linear(hidden_sizes[-1], output_size)]\n",
    "\n",
    "hidden_layers = []\n",
    "for i in range(len(hidden_sizes) - 1):\n",
    "    hidden_layers.append(nn.Linear(hidden_sizes[i], hidden_sizes[i + 1]))\n",
    "    hidden_layers.append(nn.ReLU())\n",
    "\n",
    "layers = tuple(input_layer + hidden_layers + output_layer)\n",
    "    \n",
    "\n",
    "net = Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=117, out_features=128, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=128, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.001)  # momentum=0.9\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "train_loss: 1.655 - train_accuracy: 0.352  - val_loss: 1.538 - val_accuracy: 0.402\n",
      "Epoch 2/5\n",
      "train_loss: 1.492 - train_accuracy: 0.425  - val_loss: 1.456 - val_accuracy: 0.439\n",
      "Epoch 3/5\n",
      "train_loss: 1.428 - train_accuracy: 0.452  - val_loss: 1.409 - val_accuracy: 0.458\n",
      "Epoch 4/5\n",
      "train_loss: 1.387 - train_accuracy: 0.469  - val_loss: 1.375 - val_accuracy: 0.473\n",
      "Epoch 5/5\n",
      "train_loss: 1.356 - train_accuracy: 0.482  - val_loss: 1.350 - val_accuracy: 0.484\n",
      "Finished Training\n",
      "CPU times: user 4min 1s, sys: 1.35 s, total: 4min 2s\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%time net.fit(train_loader, val_loader, criterion, optimizer, device, n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "#pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "#plt.grid(True)\n",
    "#plt.gca().set_ylim(0, 1)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('models/tensorflow_keras/ravdess_savee_tess_emovo--10_10--StandardScaler--300_relu-100_relu-10_softmax--scc_sgd_accuracy--30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
